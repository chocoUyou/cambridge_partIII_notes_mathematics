\documentclass[10pt,a4paper]{report}


\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{calrsfs}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[mathscr]{euscript}

%%%for drawing commutative diagrams.%%%%%%
\usepackage{tikz-cd}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%for changing margin
\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 

\newenvironment{proof}
{\begin{changemargin}{1cm}{0.5cm} 
	}%your text here
	{\end{changemargin}
}

\newenvironment{subproof}
{\begin{changemargin}{0.5cm}{0.5cm} 
	}%your text here
	{\end{changemargin}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\newcommand{\thm}{\textbf{Theorem) }}
\newcommand{\thmnum}[1]{\textbf{Theorem #1) }}
\newcommand{\defi}{\textbf{Definition) }}
\newcommand{\definum}[1]{\textbf{Definition #1) }}
\newcommand{\lem}{\textbf{Lemma) }}
\newcommand{\lemnum}[1]{\textbf{Lemma #1) }}
\newcommand{\prop}{\textbf{Proposition) }}
\newcommand{\propnum}[1]{\textbf{Proposition #1) }}
\newcommand{\corr}{\textbf{Corollary) }}
\newcommand{\corrnum}[1]{\textbf{Corollary #1) }}
\newcommand{\pf}{\textbf{proof) }}


\newcommand{\lap}{\triangle} %%Laplacian
\newcommand{\s}{\vspace{10pt}}
\newcommand{\bull}{$\bullet$}
\newcommand{\sta}{$\star$}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\eop}{\hfill  \textsl{(End of proof)} $\square$} %end of proof
\newcommand{\eos}{\hfill  \textsl{(End of statement)} $\square$} %end of proof


\newcommand{\intN}{\mathbb{Z}_N}
\newcommand{\nat}{\mathbb{N}}
\newcommand{\norms}[2]{\parallel #1 \parallel_{#2}}
\newcommand{\abs}[1]{\big| #1 \big|}
\newcommand{\avg}{\mathbb{E}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\borel}{\mathscr{B}}
\newcommand{\EE}{\mathscr{E}}
\newcommand{\pa}{\partial}

\renewcommand{\bar}{\overline}

\def\doubleunderline#1{\underline{\underline{#1}}}

\newcommand{\newday}{===============================================================}
\newcommand{\digression}{**********************************************************************************************}


\setlength\parindent{0pt}

\chapter*{Analysis of PDEs}
\s

Claude Warnick(cmw50)

www.dpmms.cam.ac.uk/~cmw50

Example Classes : Dr. Ivan Moyano
\s

Texts : (1)Evans. PDEs, (2)Rauch, PDEs, (3)F.John, PDEs, (4)Gilberg + Raudinger, Elliptic PDE, (5) Ladyzhenskay, The Boundary Value Problems of Mathematical Physics.
\s

=====================================================================================

(5th October 2018, Friday)
\s

\section*{Introduction}

Suppose $U \subset \reals^n$ is open. A \emph{partial differential equation} of order $k$ is an expression of the following form:
\begin{align}
F(x, u(x),Du(x),\cdots,D^{(k)}u(x))=0 \label{1}
\end{align}
Here, $F: U \times \reals\times \reals^n \times \cdots \times \reals^{n^k} \rightarrow \reals$ is a given function and $u : U \rightarrow \reals$ is the 'unknown'. We say $u\in C^k(U)$ is a classical solution of \ref{1} if \ref{1} is satisfied on $U$ when we substitute $u$ into the expression.
\s

We could also consider the case where $u:U \rightarrow \reals^p$ and $F$ takes values in $\reals^q$, then we speak of a \emph{system of PDE's}.
\s

\textbf{Examples)}
\begin{itemize}
\item[1.] The Transport Equation:
Suppose $V :\reals^{n+2} \rightarrow \reals^n$ is given.
\begin{align*}
\frac{\partial u}{\partial t}(x,t) + V(x,t,u(t,x)) \cdot D_x u (x,t) = f(x,t) \quad \text{for } x\in \reals^n
\end{align*}
is a PDE for $u: \reals^{n+1} \rightarrow \reals$. This describes evolution of some chemical produced at rate $f(x,t)$ and being advected by a flow of velocity $V(x,t,u(t,x))$.

\item[2.] The Laplace and Poisson Equations:
\begin{align*}
\Delta u(x) = \sum_{i=1}^n \frac{\partial^2 u}{\partial x_i \partial x_j}(x)=0 \quad \text{(Laplace Equation)}
\end{align*}
This describes: \begin{itemize}
\item[+] Electrostatic potential in empty space
\item[+] Static distribution of heat in a solid body
\item[+] Applications to steady flows in 2D
\item[+] Connections to complex analysis
\end{itemize}

\begin{align*}
\Delta u(x) =f(x) \quad \text{some given } f: \reals^n \rightarrow \reals \quad \text{(Poisson's Equation)}
\end{align*}
This describes: \begin{itemize}
\item[+] Electric field produced by charge distribution $f$
\item[+] Gravitational field in Newton's Theory($f$ is mass density)
\end{itemize}

\item[3.] Heat/Diffusion Equation:
\begin{align*}
\frac{\partial u}{\partial t} = \Delta u
\end{align*}
This describes evolution of temperature in a solid homogeneous body.

\item[4.] Wave Equation:
\begin{align*}
-\frac{\pa^2 u}{\pa t^2} + \Delta u =0
\end{align*}
This describe: \begin{itemize}
\item[+] Displacement of a stretched string (dimension=1)
\item[+] Ripples on surface of water (dimension=2)
\item[+] Density of air in a sound wave (dimension=3)
\end{itemize}

\item[5.] Maxwell's Equations:
With $E,B : \reals^3 \times \reals \rightarrow \reals^3$,
\begin{align*}
\nabla \cdot E = \rho & \quad \nabla \cdot B =0 \\
\nabla \times E + \frac{\pa B}{\pa t} =0 & \quad \nabla \times B - \frac{\pa E}{\pa t} = J
\end{align*}
$\rho$, $J$ are charge density/current respectively, are given.

\item[6.] Ricci Flow:
\begin{align*}
\pa_t g_{ij} = -2R_{ij}
\end{align*}
where $g_{ij}$ is a Riemannian metric, $R_{ij}$ is its Ricci curvature.

\item[7.] Minimal Surface Equation:
For $u: \reals^2 \rightarrow \reals$,
\begin{align*}
\text{div}(\frac{Du}{\sqrt{1-|Du|^2}}) =0
\end{align*}
Condition for the graph $\{ (x,y,u(x,y)) \}$ to locally extremise area.

\item[8.] Eikonal Equation:
for $U\subset \reals^3$ and $u:U\rightarrow \reals$
\begin{align*}
|Du|=1
\end{align*}
Level sets parametrise a wave-front moving according to the ray theory of light. 

\item[9.] Schr\"{o}dinger's Equation:
For $u:\reals^3 \times \reals \rightarrow \mathbb{C} \equiv \reals^2$,
\begin{align*}
i\frac{\pa u}{\pa t} + \Delta u - Vu =0
\end{align*}
for $V: \reals^3\rightarrow \reals$ given. $u$ is the wavefunction of a quantum mechanical particle moving in a potential $V$.

\item[10.] Einstein's Equations for General Relativity:
\begin{align*}
R_{\mu \nu}[g] =0
\end{align*}
where $g$ is Lorentzian metric. $R_{\mu \nu}$ is Ricci tensor. This describes gravitational field in vacuum.

\item[-.] There are Many more examples.
\end{itemize}

\subsection*{Data and Well-Posedness}
In all examples, there is extra information required beyond the equation. We call this the \emph{data}. An important question is what data is appropriate. We typically ask of a PDE problem that:
\begin{itemize}
\item[a)] A solution exists,
\item[b)] for given data the solution is unique,
\item[c)] the solution depends on the data continuously.
\end{itemize}
If these hold, we say the problem is 'well-posed'. To make these precise, we have to (usually) specify function spaces for the data and solution to belong to.
\s

====================================================================
8th October, Monday
\s

Let $U \subset \reals^n$, $u: U \rightarrow \reals$ be unknown. Then our system of interest will be
\begin{align}
F(x; u,Du,\cdots, D^k u)=0 \label{thePDE}
\end{align}
\s

\textbf{Notations) } Let $\alpha = (\alpha_1, \cdots, \alpha_n) \in \mathbb{N}^n$ be a multi-index(where $\mathbb{N} =\{ 0,1,2,3,\cdots\}$). Then we let:
\begin{itemize}
\item $D^{\alpha}f(x) = \frac{\partial^{| \alpha |} f}{\partial x_1^{\alpha_1} \cdots \partial x_n^{\alpha_n}}$ where $|\alpha| = \alpha_1 + \cdots + \alpha_n$ is the order of $\alpha$.
\item For $x \in \reals^n$, $x^{\alpha} = x_1^{\alpha_1} \times \cdots \times x_n^{\alpha_n}$
\item $\alpha! = \alpha_1! \cdots \alpha_n!$.
\item For $\beta = (\beta_1, \cdots, \beta_n)$, $\beta \leq \alpha$ is equivalent to having $\beta_k \leq \alpha_k$ for all $k$.
\end{itemize}
\s

\subsection*{Classifying PDEs}
\begin{itemize}
\item We say (\ref{thePDE}) is \textbf{linear} if $F$ is a linear function of $u$ and its derivatives. We can write (\ref{thePDE}) as 
\begin{align*}
\sum_{|\alpha \leq k} a_{\alpha}(x) D^{\alpha}u(x) = f(x)
\end{align*}
\item We say (\ref{thePDE}) is \textbf{semi-linear} if it is of the form
\begin{align*}
\sum_{|\alpha \leq k} a_{\alpha}(x) D^{\alpha}u(x) + a_0(x;u(x),\cdots,D^{k-1}u(x)) = 0
\end{align*}|
\item We say (\ref{thePDE}) is \textbf{quasi-linear} if it is of the form
\begin{align*}
\sum_{|\alpha \leq k} a_{\alpha}\big(x;u(x),\cdots,D^{k-1}u(x) \big) D^{\alpha}u(x) + a_0(x;u(x),\cdots,D^{k-1}u(x)) = 0
\end{align*}|
\item We say (\ref{thePDE}) is \textbf{fully non-linear} if its not linear, semi-linear, nor quasi-linear
\end{itemize}
\s

\textbf{Examples)}
\begin{itemize}
\item $\Delta u = f$ is linear
\item $\Delta u =u^3$ is semi-linear
\item $uu_{xx} + u_x u_{yy} = f$ is quasi-linear
\item $u_{xx}u_{yy} - u_{xy}^2 = f$ is fully non-linear.
\end{itemize}
\s

\subsection*{Cauchy-Kovalevskaya Theorem}
For motivation, we recall some ODE theory. Fix $U \subset \reals^n$, and assume $f:U \rightarrow \reals^n$ is given. Consider the ODE
\begin{align}
\dot{u}(t) = f(u(t)), u(0)=u_0 \in U \label{theODE}
\end{align}
with $u : I \subset \reals \rightarrow U$.
\s

\thm (Picard-Lindel\"{o}f) Suppose there exist $r,K>0$ s.t. $B_r(u_0) = \{ w\in \reals^n : |w-u_0|<r\}$ and $|f(x)-f(y) \leq K|x-y|$ for all $x,y \in B_r(x_0)$. Then there exists $\epsilon >0$(depending in $r$ and $K$) and a unique $C^1$-function $u : (-\epsilon,\epsilon)\rightarrow U$ solving (\ref{theODE}).

\pf Use $U$ solves (\ref{theODE}), then 
\begin{align}
u(t) = u_0 + \int_0^t f(u(s))ds \label{equivODE}
\end{align}
and conversely, if $U$ is $C^0$ and solves (\ref{equivODE}), then in fact $U$ is $C^1$ by FTC, and $u$ solves (\ref{theODE}).(in context of PDEs, this is called \emph{weak formulation})

Then our solution, if exists, is a fixed point of the map $B : w \mapsto u_0 + \int_0^t f(w(s))ds$.(~use Banach fixed point theorem)
\s

\textbf{Observations:}
\begin{itemize}
\item[-] We start by reformulating the problem in a weak form and find a unique $C^0$ solution. Then $C^1$ the regularity follows a posteriori.
\item[-] to construct the fixed point map, we solve the linear problem $\dot{w}(t) = f(w(t))$.
\end{itemize}
\s

Lets consider an alternative approach to solving (\ref{theODE}). Assuming $f$ is differentiable, we have
\begin{align*}
u^{(1)}(t) &= f(u(t)) \\
u^{(2)}(t) &= f'(u(t))\dot{u}(t) \\
u^{(3)}(t) &= f''(u(t))(\dot{u}(t))^2 + f'(u(t))\ddot{u}(t) \\
&\vdots \\
u^{(k)}(t) &= f_k(u(t), \dot{u}(t),\cdots, u^{(k-1)})(t))
\end{align*}
So in principle, given $u(0) = u_0$, we can determine $u_k = u^{(k)}(0)$ for all $k \geq 0$. \emph{Formally} at least, we can write
\begin{align}
u(t) = \sum_{k=0}^{\infty} u_k t^k / k! \label{seriesSoln}
\end{align}
ignoring the issues of convergence. Call this a \textbf{formal power series solution}. When will this agree with the Picard-Lindel\"{o}f solution we have constructed?
\s

\thm(Cauchy-Kovalevskaya, for the case of ODEs) The series in (\ref{seriesSoln}) converges to a solution of (\ref{theODE}) in a neighbourhood of $t=0$ if $f$ is real analytic at $u_0$.

-This will follow from a more general result later.
\s

\defi Let $U \subset \reals^n$ be open and suppose $f: U \rightarrow \reals$. $f$ is called \textbf{real analytic} near $x_0 \in U$ if $\exists r >0$ and constants $f_{\alpha}$($\alpha$ are multi-indices) such that
\begin{align*}
f(x) = \sum_{\alpha}f_{\alpha} (x-x_0)^{\alpha} \quad \text{for } x \in B_r(x_0)
\end{align*}
\s

\textbf{Note:} if $f$ is real analytic, then it is $C^{\infty}$. Furthermore, the constants $f_{\alpha}$ are given by $f_{\alpha} = D^{\alpha}f(x_0) /\alpha!$. Thus $f$ equals its Taylor expansion about $x_0$, in a neighbourhood of $x_0$.
\begin{align*}
f(x) = \sum_{\alpha} \frac{D^{\alpha}f(x_0)}{\alpha!} (x-x_0)^{\alpha} \quad \text{for } x \in B_r(x_0)
\end{align*}
By translation, we usually assume $x_0 =0$
\s

\newday

(10th October, Wednesday)
\s

$\bullet$ Last lecture : $U \subset \reals^n$ open, $f: U \rightarrow \reals$ is real analytic at $x_0 \in U$ if $\exists f_{\alpha} \in \reals$, $r>0$ s.t.
\begin{align*}
f(x)  = \sum_{\alpha} f_{\alpha}(x-x_0)^{\alpha} \quad \forall |x-x_0|<r
\end{align*}
\s

\textbf{Properties of real analytic functions}
\begin{itemize}
\item $f$ is real analytic at $x_0$ if and only if $\exists s>0$ and $C,\rho>0$ such that:
\begin{align*}
\sup_{|x-x_0|< s}\big| D^{\alpha}f(x) \big| \leq C \frac{|\alpha|!}{\rho^{|\alpha|}}
\end{align*}
\item If $f$ is RA(real analytic) at $x_0$, it is RA for all $x$ close enough to $x_0$.
\item If $f: U \rightarrow \reals$ is real analytic everywhere on a connected set $U$, then $f$ is determined by its values on any open subset of $U$. (Or by its Taylor expansion at a single point.)
\end{itemize}
\s

\textbf{Example :} If $r>0$ set
\begin{align*}
f(x) = \frac{r}{r-(x_1 + \cdots + x_n)} \quad \text{for } |x|<r/\sqrt{n}
\end{align*}
Then for $|x| < r/\sqrt{n}$,
\begin{align*}
f(x) &= \frac{1}{1-(x_1 + \cdots +x_n)/r} = \sum_{k=0}^{\infty} \Big( \frac{x_1 +\cdots +x_n}{r} \Big)^k = \sum_{k=0}^{\infty} \frac{1}{r^k} \sum_{|\alpha| = k} \begin{pmatrix}
|\alpha| \\
\alpha
\end{pmatrix} x^{\alpha} \\
& =  \sum_{\alpha} \frac{|\alpha|!}{r^{|\alpha|}\alpha!} x^{\alpha}
\end{align*}
by multinomial theorem. This is valid for $|x_1+\cdots +x_n|/r <1$, which holds for $|x|<r/\sqrt{n}$. In fact, on this domain, the series converges absolutely. Indeed :
\begin{align*}
\sum_{\alpha} \frac{|\alpha|!}{r^{|\alpha|}\alpha!} |x|^{\alpha} = \sum_{k=0}^{\infty} \Big( \frac{|x_1|+\cdots+|x_n|}{r} \Big)^k < \infty
\end{align*}
since $|x_1|+\cdots +|x_n| \leq |x| \sqrt{n} <r$.
\s

\defi Let $f = \sum_{\alpha} f_{\alpha} x^{\alpha}$, $g= \sum_{\alpha} g_{\alpha} x^{\alpha}$ be two formal power series. We say $g$ \textbf{majorises} $f$, written $g \gg f$ if
\begin{align*}
\big|f_{\alpha} \big| \leq g_{\alpha}
\end{align*}
for all $\alpha$, and say that $g$ is a \textbf{majorant} of $f$.
\s

\lem \begin{itemize}
\item[(i)] If $g\gg f$ and $g$ converges for $|x|<r$ then $f$ also converges (absolutely) for $|x| <r$.
\item[(ii)] If $f$ converges for $|x|<r$, then for any $s\in (0,r/\sqrt{n})$, $f$ has a majorant that converges for $|x|<s/\sqrt{n}$.($n$ is the dimension of the space)
\end{itemize}
\begin{proof}
\pf \begin{itemize}
\item[(i)] We note that
\begin{align*}
\sum_{\alpha} \abs{f_{\alpha} x^{\alpha}} &\leq \sum_{\alpha} \abs{f_{\alpha}} |x_1|^{\alpha_1} \cdots |x_n|^{\alpha_n} \\
&\leq \sum_{\alpha} g_{\alpha} \tilde{x}^{\alpha}
\end{align*}
where $\tilde{x} = (|x_1|,\cdots,|x_n|)$. Now $|\tilde{x}| = |x|  <r$ so $\sum_{\alpha} g_{\alpha} \tilde{x}^{\alpha}$ converges, hence $\sum_{\alpha} \abs{f_{\alpha} x^{\alpha}}$ converges. Hence $f$ converges on $|x|<r$ absolutely. 
\item[(ii)] Pick $s$ s.t. $0<s\sqrt{n} <r$, and set $y=s(1,\cdots,1)$. Then $|y| = s\sqrt{n} <r$. Hence $\sum_{\alpha}f_{\alpha}y^{\alpha}$ converges. A convergent series has bounded terms, $\exists C>0$ s.t. $\abs{f_{\alpha}y^{\alpha}} \leq C$ for all $\alpha$, and therefore
\begin{align*}
\abs{f_{\alpha}} \leq \frac{C}{y_1^{\alpha_1} \cdots y_n^{\alpha_n}} = \frac{C}{s^{|\alpha|}} \leq \frac{C |\alpha|!}{s^{\alpha} \alpha!}
\end{align*}
But then $g(x)$ defined by
\begin{align*}
g(x) = \frac{Cs}{s-(x_1 + \cdots + x_n)}  = C \sum_{\alpha} \frac{|\alpha|!}{s^{\alpha}\alpha!}x^{\alpha}
\end{align*}
majorises $f$ and converges for $|x|<s/\sqrt{n}<r/n$.
\end{itemize}

\eop
\end{proof}
\s

\textbf{Remark :} If $f = (f^1, \cdots, f^m)$ and $g =(g^1, \cdots, g^m)$ are formal power series, then we say
\begin{align*}
g\gg f \quad \text{if} \quad g^i \gg f^i \quad i=1,\cdots,m
\end{align*}
\s

\subsection*{Cauchy-Kovalevskaya for First Order Systems}
We will study a problem that generalises the Cauchy problem for ODEs we have already discussed.
\s

As coordinates on $\reals^n$ we take $(x',t) = x$ where
\begin{align*}
x'=(x_1,\cdots,x_{n-1}) \in \reals^{n-1}, \quad t=x^n \in \reals
\end{align*}
Set
\begin{align*}
B^n_r = \{t^2 +|x'|^2 <r^2 \}, \quad B_r^{n-1} = \{|x'|<r, t=0 \}
\end{align*}
\s

\renewcommand{\vec}{\underline}
We consider a system of equations for unknown $\vec{u}(x) \in \reals^m$. More concretely, we seek a solution to
\begin{align} 
\vec{u}_t &= \sum_{j=1}^{n-1} \doubleunderline{B}_j (\vec{u},x') \cdot \vec{u}_{x_j} + \vec{c}(\vec{u},x') \quad \text{on } B_r^n \label{5} \\
\vec{u} &= 0 \quad \text{on } B_r^{n-1} \nonumber
\end{align}
where $\vec{u}_{x_j}=\partial u/\partial x_j$ etc. We assume that we are given the real analytic functions
\begin{align*}
\doubleunderline{B}_j :& \reals^m \times \reals^{n-1} \rightarrow \text{Mat}(m\times m) \\
\vec{c} :& \reals^m \times \reals^{n-1} \rightarrow \reals^m
\end{align*}
(these functions do not have to defined on the entire space, but just have to be defined on $\reals^n \times B^{n-1}_r$)

Note we assume $\doubleunderline{B}_j$ and $\vec{u}$ do not depend explicitly on $t$. We can always introduce $u^{m+1}$ satisfying $\partial_t u^{m+1} =1$, $u^{m+1} =0$ on $B_r^{n-1}$ and extending the system.

\quad We will write $\doubleunderline{B}_j = ((b_j^{kl}))$ and $\vec{c}  = (c^1, \cdots, c^m)^T$. Then in components (\ref{5}) reads:
\begin{align*}
u_t^k = \sum_{j=1}^{n-1} \sum_{l=1}^m b_j^{kl}(\vec{u},x')u_{x_j}^l + c^k(\vec{u},x') \quad k=1,\cdots, m
\end{align*}
\s

\textbf{Examples :} Take $m=2$, write $\vec{u} = (f, g)^T$.
\begin{itemize}
\item[(a)] \begin{align*}
\begin{cases}
f_t= g_x + F\\
g_t = f_x
\end{cases}
\end{align*}
together imply $f_{tt} - f_{xx} = F_t$
\item[(b)] \begin{align*}
\begin{cases}
f_t= -g_x + F\\
g_t = f_x
\end{cases}
\end{align*}
together imply $f_{tt} + f_{xx} = F_t$. (Note $F=0$ gives Cauchy-Riemann equation)
\end{itemize}
\s

\thm (Cauchy-Kovalevskaya) Assume $\{\doubleunderline{B}_j \}_{j=1}^{n-1}$ and $\vec{c}$ are real analytic. Then for sufficiently small $r>0$ there exists a unique real analytic function $\vec{u} : B_r^n \rightarrow \reals^m$ solving the problem (\ref{5}).
\s

\newday

(12th October, Friday)
\s

\thm (Cauchy-Kovalevskaya) Assume $\{\doubleunderline{B}_j \}_{j=1}^{n-1}$ and $\vec{c}$ are real analytic. Then for sufficiently small $r>0$ there exists a unique real analytic function $\vec{u} : B_r^n \rightarrow \reals^m$ solving the problem (\ref{5}).
\begin{proof}
\pf \begin{itemize}
\item[1.] The strategy will be to write
\begin{align}
\vec{u}(x)  = \sum_{\alpha} \vec{u}_{\alpha}x^{\alpha} \label{6}
\end{align}
and compute coefficients
\begin{align*}
\vec{u}_{\alpha} = \frac{D^{\alpha } \vec{u}(0)}{\alpha !}
\end{align*}
in terms of $\doubleunderline{B}_j$, $\vec{c}$ and show that the series (\ref{6}) converges on $B_r^n$ for $r$ small enough.

\item[2.] As $\doubleunderline{B}_j$ and $\vec{c}$ are real analytic, we can write
\begin{align*}
\doubleunderline{B}_j(z,x') &= \sum_{\gamma, \delta} \doubleunderline{B}_{j,\gamma,\delta}z^{\gamma}(x')^{ \delta} \quad \gamma\in \mathbb{N}^m,\delta \in \mathbb{N}^{n-1} \text{ multiindices} \\
\vec{c}(z,x') & = \sum_{\gamma, \delta} \vec{c}_{\gamma, \delta} z^{\gamma}(x')^{ \delta}
\end{align*}
where these power series converge for $ |z|^2 + |x'|^2 <s^2$, wlog $s>r$.
Thus:
\begin{align}
\doubleunderline{B}_{j, \gamma, \delta} &= \frac{D_z^{\delta} D_{x'}^{\delta} \doubleunderline{B}_{j}(0,0)}{\gamma ! \delta !} \label{7}\\
\vec{c}_{\gamma, \delta} &= \frac{D_z^{\delta} D_{x'}^{\delta} \vec{c}(0,0)}{\gamma ! \delta !} \nonumber
\end{align}

\item[3.] Since $\vec{u} \equiv 0$ on $\{ t=x^n =0 \}$, we have
\begin{align*}
\vec{u}_{\alpha} = \frac{D^{\alpha}\vec{u}(0)}{\alpha !} = 0
\end{align*}
for all multi-indices $\alpha$ with $\alpha_n=0$.

Now, we use the evolution equation (\ref{5}) to deduce
\begin{align*}
\vec{u}_{x_n}(0)  = \vec{u}_t (0) = \sum_{j=1}^{n-1} \doubleunderline{B}_j(\vec{u}(0),0) \vec{u}_{x_j}(0) + \vec{c}(\vec{u}(0),0) = \vec{c}(0,0)
\end{align*}
Fix $i\in \{1,2,\cdots, n-1\}$, differentiate (\ref{5}) with respect to $x^i$ : 
\begin{align*}
\vec{u}_{tx_i} = \sum_{j=1}^{n-1} \Big[ & \partial_{x_i} \doubleunderline{B}_j(\vec{u},x') \vec{u}_{x_j} + \big( \sum_{i=1}^m \partial_{z_i}\doubleunderline{B}_j (\vec{u},x') \frac{\partial u^i}{\partial x^j} \vec{u}_{x_j} \big) + \doubleunderline{B}_j(\vec{u},x')\vec{u}_{x_i x_j} \Big] \\
& + \partial_{x_i} \vec{c}(\vec{u},x') + \sum_{i=1}^m \partial_{z_l} \vec{c}(\vec{u},x') \frac{\partial u^{l}}{\partial x^i} \\
\vec{u}_{tx_i}(0) = \partial_{x_i} & \vec{c}(0,0)
\end{align*}
Iterating this, we deduce $D^{\alpha}\vec{u}(0) = D^{\delta} \vec{c}(\vec{0},0)$ where $\alpha=(\delta,1)$. 

\item[4. ] Now, suppose $\alpha = (\delta,2)$, for $\delta \in \mathbb{N}^{n-1}$. Then
\begin{align*}
D^{\alpha} u^k &= D^{\delta}(u^k_{x_n x_n}) = D^{\delta}(u^k_t)_t \\
&= D^{\delta}\Big( \sum_{j=1}^{n-1}\sum_{l=1}^m b_j^{kl} u_{x_j}^l + c^k \Big)_t \\
&= D^{\delta}\Big( \sum_{j=1}^{n-1} \sum_{i=1}^m \Big[ b_j^{kl} u_{x_j t}^l + \sum_{p=1}^m (b_j^{kl})_{z_p} u_{x_j}^l u_t^p \Big] + \sum_{p=1}^m c_{z_p}^k u_t^p  \Big)
\end{align*}
so
\begin{align*}
D^{\alpha} u^k (0) = D^{\alpha} \Big( \sum_{j=1}^{n-1} \sum_{i=1}^m  b_j^{kl} u_{x_j t}^l + \sum_{p=1}^m c_{z_p}^k u_t^p \Big) \Big|_{x=0,\vec{u}=0}
\end{align*}
Now crucially, the expression on the right can be expanded to produce a polynomial with non-negative coefficients involving derivative of $\doubleunderline{B}_j$ and $\vec{c}$, and derivatives $D^{\beta} \vec{u}$ where $\beta_n \leq 1$. More generally, for each multi-index $\alpha$ and each $k\in \{1,\cdots, n\}$, we can compute
\begin{align*}
D^{\alpha}u^k(0) = p_{\alpha}^k \Big( D_z^{\alpha} D^{\delta}_{x'}\doubleunderline{B}_j, D_z^{\alpha}D_{x'}^{\delta} \vec{c}, D^{\beta} \vec{u}\Big) \big|_{x=0,\vec{u}=0}
\end{align*}
where $\beta_n\leq \alpha_n -1$ and $p_{\alpha}^k$ is some polynomial in its arguments with non-negative coefficients. Equivalently, for each $\alpha, k$
\begin{align*}
u_{\alpha}^k = q_{\alpha}^k \big( \doubleunderline{B}_{j,\alpha,\delta},\vec{c}_{\gamma, \delta},u_{\beta}  \big)
\end{align*}
where $q_{\alpha}^k$ is a polynomial with non-negative coefficients, with $\beta_n \leq \alpha_n -1$.

\item[5.] We have shown that if a solution exists, we can compute all derivatives at $0$ in terms of known quantities. We will construct a series which majorises the formal sum $\sum_{\alpha} u_{\alpha}x^{\alpha}$.

\quad First suppose 
\begin{align*}
\doubleunderline{B}_j^{*} \gg \doubleunderline{B}_j \quad \vec{c}^* \gg \vec{c}
\end{align*}
where
\begin{align*}
\doubleunderline{B}_j^{*} &= \sum_{\gamma, \delta} \doubleunderline{B}_{j,\gamma,\delta}^{*} z^{\gamma} (x')^{\delta} \\
\vec{c}^* &= \sum_{\gamma, \delta} \vec{c}_{\gamma,\delta}^{*} z^{\gamma} (x')^{\delta}
\end{align*}
Assume these converge for $|z|^2 + |x'|^2 <s^2$ (decrease $s$ if necessary). For all $j,\gamma, \delta, k,l$,
\begin{align*}
0\leq |B^{kl}_{j,\gamma,\delta}| \leq (B^*)^{kl}_{j,\gamma,\delta}, \quad 0\leq |c^k_{\gamma, \delta} | \leq (c^*)^{kl}_{\gamma, \delta}
\end{align*}
We consider the modified problem:
\begin{align*}
\vec{u}^*_t &= \sum_{j=1}^{n-1} \doubleunderline{B}^*_j (\vec{u}^*, x') \vec{u}^*_{x_j} + \vec{c}^*(\vec{u}^*,x') \quad \text{for } |x| <r \\
\vec{u}^* &= \vec{0} \quad \text{on } B_r^{n-1}
\end{align*}
As above, seek a real analytic solution
\begin{align*}
\vec{u}^* = \sum_{\alpha} \vec{u}^*_{\alpha} x^{\alpha} \quad \text{where } \vec{u}^*_{\alpha} = \frac{D^{\alpha}\vec{u}(0)}{\alpha !}
\end{align*}

\item[6.] We claim $0\leq |u_{\alpha}^k| \leq (u^*)^{k}_{\alpha}$ for all $\alpha \in \mathbb{N}^n$.

We do this by proof by induction on $\alpha_n$.

For $\alpha_n =0$, $u_{\alpha}^* = u_{\alpha} =0$

For the induction step: (for $\beta_{\alpha} \leq \alpha_n -1$)
\begin{align*}
|u_{\alpha}^k| &= |q_{\alpha}^k(\doubleunderline{B}_{j,\gamma,\delta}, \vec{c}_{\gamma,\delta},\vec{u}_{\beta})| \\
&\leq q_{\alpha}^k ( |B_{j,\gamma,\delta}^{kl}|,|C_{\gamma,\delta}^k|,|u^k_{\beta}|) \\
&\leq q_{\alpha}^k ((B^*)^{kl}_{j,\gamma,\delta},(c^*)^{k}_{\gamma,\delta},(u^*)^{k}_{\beta}) \\
&= (u*)^{k}_{\alpha}
\end{align*}
Using positivity of coefficients of $q$ and induction assumption. Thus $\vec{u}^* \gg \vec{u}$. Remains to show we can find $\doubleunderline{B}_{j}^*$, $\vec{c}^*$ s.t. a solution $\vec{u}^*$ exists and converges near 0.
\end{itemize}
\end{proof}

\newday

(15th October, Monday)
\s

Last lecture :
\begin{itemize}
\item a formal power series solution $\vec{u} = \sum_{\alpha} \vec{u}_{\alpha} x^{\alpha}$ exists.

\item If $\doubleunderline{B}^*_j \gg \doubleunderline{B}_j$, $\vec{c}^* \gg \vec{c}$ and $\vec{u}^*$ satisfies
\begin{align*}
\vec{u}^*_t &= \sum_{j=1}^{n-1} \doubleunderline{B}^*_j (\vec{u}^*, x') \vec{u}^*_{x_j} + \vec{c}^*(\vec{u}^*,x') \quad \text{for } |x| <r \\
\vec{u}^* &= \vec{0} \quad \text{on } B_r^{n-1}
\end{align*}
then the power series for $\vec{u}^* = \sum_{\alpha} \vec{u}^*_{\alpha} x^{\alpha}$.
\end{itemize}

\begin{proof}
\textbf{proof, continued)} To complete the proof, it suffices to show that for any $\doubleunderline{B}_j$, $\vec{c}$, we can find $\doubleunderline{B}^*_j$, $\vec{c}^*_j$ such that the corresponding $\vec{u}^*_j$ is a convergent series.

\quad We make a particular choice for $\doubleunderline{B}^*_j$, $\vec{c}^*$. For this we recall from an earlier lemma that
\begin{align*}
\doubleunderline{B}^*_j &= \frac{Cr}{r-(x_1+\cdots+x_{n-1}) - (z_1 + \cdots + z_m)} \begin{pmatrix}
1 & 1& \cdots 1 \\
\vdots & & \ddots \vdots \\
1 & 1 & \cdots 1
\end{pmatrix} \\
\vec{c}^* &= \frac{Cr}{r-(x_1+\cdots+x_{n-1}) - (z_1 + \cdots + z_m)} (1,\cdots, 1)^T
\end{align*}
will majorise $\doubleunderline{B}_j$, $\vec{c}$, provided $C$ is large enough, $r$ is small enough and $\doubleunderline{B}^*_j$, $\vec{c}^*$ are given by convergent series for $|x'|^2 + |z|^2 <r^2$. With these choices of majorants, the modified equation takes the form :
\begin{align*}
(u^*)^k_t  &= \frac{Cr}{r-(x_1+\cdots+x_{n-1}) - ((u^*)^1 + \cdots + (u^*)^m)} (\sum_{j,l} \big( u^*)^l_{x_j} +1 \big) \quad \text{for } |x'|^2 + t^2 <r^2 \\
u^* &= 0 \quad \quad \quad \quad \text{for } t=0,|x'|<r
\end{align*}
This problem has an explicit solution.
\begin{align*}
\vec{u}^* = v^* (1,\cdots,1)^T
\end{align*}
where
\begin{align*}
v^* = \frac{1}{mn} \Big( r - (x_1+ \cdots + x_{n-1}) - \sqrt{(r-(x_1+\cdots + x_{n-1}))^2 - 2nmCrt} \Big)
\end{align*}
(\emph{Check this is indeed the solution!!}) $v^*$ is real analytic for $|x'|^2 + t^2 < r^2$, provided $r$ is small enough. Hence $\vec{u}^*$ is given by a convergent series since $\vec{u}^* \gg \vec{u}$. Our formal power series for $\vec{u}$ converges.

\quad Initial condition hold for $\vec{u}$ since
\begin{align*}
\vec{u}_{\alpha} = \vec{0} \quad \text{if} \quad \alpha_n =0
\end{align*}
%배고프다 ㅜㅜㅜㅜ
Moreover, the functions $\vec{u}_t$ and $\sum_{j=1}^{n-1} \doubleunderline{B}_j(\vec{u},x') \vec{u}_{x_j} + \vec{c}(\vec{u},x')$ are both real analytic near 0 and by construction, have the same Taylor expansion. Hence they must agree on a neighbourhood of 0, so the equation holds in some ball about 0.

\eop 
\end{proof}
\s

\subsection*{Reduction to a First Order System}

\textbf{Example) }
\begin{proof}
\quad Consider the PDE problem for $u:\reals^3 \rightarrow \reals$
\begin{align}
u_{tt} &= uu_{xy} - u_{xx} + u_t  \label{11} \\
u\big|_{t=0}  &= u_0  \nonumber \\
u_t \big|_{t=0} &= u_1 \nonumber
\end{align}
where $u_0, u_1:\reals^2 \rightarrow \reals$ are given real analytic functions (near 0).

First note that $f=u_0 + tu_1$ is analytic in a neighbourhood of $0\in \reals^3$ and $f\big|_{t=0} = u_0$, $f_t\big|_{t=0} = u_1$. 

Set $w = u-f$, then
\begin{align*}
& w_{tt} = ww_{xy}  - w_{xx} + w_t + fw_{xy} + f_{xy} w + F\\
& w\big|_{t=0} = w_t \big|_{t=0} =0
\end{align*}
where $F= ff_{xy} - f_{xx} +f_t -f_{tt}$.

Let $(x,y,t) = (x^1,x^2,x^3)$ and set $\vec{u} = (w,w_x,w_y,w_t) = (u^1,u^2,u^3,u^4)$. Then

\begin{align*}
& u^1_{x^3} = w_t = u^4 \\
& u^2_{x^3} = w_{xt} = u^4_{x_1} \\
& u^3_{x^3} = w_{yt} = u^4_{x_2} \\
& u^4_{x^3} = w_{tt} = u^1 u^2_{x^2} - u^2_{x^1}+ u^4+ fu^2_{x^2} + f_{xy}u^1 + F
\end{align*}
Now, defining:
\begin{align*}
& \doubleunderline{B}_1 = \begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 \\
0 & -1& 0 & 0
\end{pmatrix},\quad \doubleunderline{B}_2 = \quad \begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 \\
u_1 +f & 0 & 0 & 0 
\end{pmatrix} \\
& \quad \\
& \vec{c} = (u^4, 0, 0, u^4 + f_{xy}u^1 +F)^T
\end{align*}
The system of equations is in the form
\begin{align*}
\vec{u}_{x_2} = \sum_{j=1}2 \doubleunderline{B}_j \vec{u}_{x_j} + \vec{c}
\end{align*}
where $\doubleunderline{B}_j$, $\vec{c}$ are real analytic near 0. By Cauchy-Kovalevskaya, a real analytic solution to (\ref{11}) exists near 0.
\end{proof}
\s

\textbf{Note :} this procedure relied on 
\begin{itemize}
\item[(a)] being able to solve for $u_{tt}$,
\item[(b)] $u_{tt}$ depending on at most two derivatives of $u$ (in a quasilinear fashion)
\end{itemize}
\s

\quad More generally, suppose we wish to solve the quasilinear problem :
\begin{align*}
& \sum_{|\alpha|=k} a_{\alpha} (D^{k-1}u,\cdots, u, x) D^{\alpha}u + a_0 (D^{k-1}u, \cdots, u,x) = 0 \quad \text{for } |x|<r \\
&  u = \frac{\partial u}{\partial x_n} =  \cdots = \frac{\partial^{k-1} u}{\partial x_n^{k-1}} = 0 \quad \quad \text{for } |x'| <r,\, x_n=0
\end{align*}
called a \textbf{Cauchy problem}.

\quad We introduce
\begin{align*}
\vec{u} = (u,\frac{\partial u}{\partial x_n}, \cdots, D^{\alpha}u,\cdots )_{|\alpha|\leq k-1} = (u^1,\cdots, u^m)
\end{align*}
$\vec{u}$ contains all derivative of $u$ up to order $k-1$. Wlog, (by changing the order if necessary) put $u^m = \partial^{k-1} u / \partial x_n^{k-1}$. For $j<m$, we can compute $\partial u^j / \partial x^n$ in terms of $\partial u^l /\partial x^p$ for some $l\in \{1,\cdots, m\}$ and $p<n$.

\quad To computed $\partial u^m / \partial x_n$ we need to use the equation. Suppose that
\begin{align*}
a_{(0,\cdots,0,k)}(0,\cdots, 0) \neq 0
\end{align*}
Then we can write the equation as :
\begin{align*}
\frac{\partial^k u}{\partial x^k_n} = \frac{-1}{a_{(0,\cdots,k)} (D^{k-1}u,\cdots,u,x)}\Big[\sum_{|\alpha|=k, \alpha_n <k} a_{\alpha} D^{\alpha} u + a_0  \Big]
\end{align*}
Assuming $a_{\alpha}$ are real analytic, the denominator will be non-zero near the origin. The RHS can be written in terms of $\frac{\partial u^l}{\partial x^p}$ for $p<n$ and $\vec{u}$. We see we can write the equation as a first ordered system for $\vec{u}$, \emph{provided}(this condition is important! would come back to this later)
\begin{align*}
a_{(0,\cdots, k)}(0,\cdots, 0) \neq 0 \quad \text{(non-characteristic condition)}
\end{align*}
In this case we can apply Cauchy-Kovalevskaya.
\s

\newday

(17th October, Wednesday)
\s

(Problem sheet 1 handed out. Example classes sign-up. First example class (probably) at Thur/Fri next week)
\s

\subsection*{Cauchy Problems for Quasilinear Equations with Data on a Surface}

We say $\Sigma \subset \reals^n$ is a real analytic \textbf{hypersurface} near $x\in \Sigma$ if there exists $\epsilon >0$ and a real analytic map $\Phi : B_{\epsilon } (x) \rightarrow U \subset \reals^n$ where $U = \Phi(B_{\epsilon}(x))$ such that
\begin{itemize}
\item $\Phi$ is bijective, and the inverse $\Phi^{-1} : U\rightarrow B_{\epsilon}(x)$ is real analytic.
\item $\Phi (\Sigma \cap B_{\epsilon}(x)) = \{x_n=0 \} \cap U$.
\end{itemize}
%(in fact non-singularity of derivative of $\Phi$ automatically implies invertibility and the analyticity of the inverse - see https://www.encyclopediaofmath.org/index.php/Real_analytic_function#Implicit_and_inverse_function_theorems)
We think of $\Phi$ as 'straightening out the boundary'. 
\s

There are many examples, e.g. $\{|x|=1\}$.
\s

Let $\gamma$ be the unit normal to $\Sigma$ and suppose $u$ solves
\begin{align}
& \sum_{|\alpha| =k} a_{\alpha}(D^{k-1}u, \cdots, u,x)D^{\alpha} u + a_0(D^{k-1}u, \cdots, u,x) =0 \quad \text{in } B_{\epsilon}(x) \label{dagger}\\
& u= \gamma^i \partial_i u = \cdots =(\gamma^i \partial_i)^{k-1} = 0 \quad \text{on } \Sigma \nonumber
\end{align}
(note that the boundary condition is equivalent to having $D^{\alpha} u =0$ for all $|\alpha| <k$ on $\Sigma$.)
\s

Define $v(y) = u(\Phi(y)) \quad \Leftrightarrow \quad u(x) = v(\Phi^{-1}(x))$. Note
\begin{align*}
&\frac{\pa v}{\pa x^i} = \frac{\pa u}{\pa y^j} \frac{\pa \Phi^j}{\pa x^i} \\
&\frac{\pa^2 v}{\pa x^i \pa x^k} = \frac{\pa u^2}{\pa y^j \pa y^i} \frac{\pa \Phi^j}{\pa x^i} \frac{\pa \Phi^l}{\pa x^k} + \frac{\pa u}{\pa y^j} \frac{\pa^2 \Phi^j}{\pa^i \pa x^k} \quad \text{etc.}
\end{align*}
So we can compute $D^{\alpha} u$ as a linear combination of $D^{\beta}v$ for $|\beta| \leq |\alpha|$, with coefficients depending on $\Phi$. So if $u$ solves (\ref{dagger}), then $v$ will solve 
\begin{align*}
\sum_{|\alpha| =k} b_{\alpha}(D^{k-1}v, \cdots, v, x)D^{\alpha}v + b_0 (D^{k-1}v, \cdots, v, x) =0
\end{align*}
Moreover,
\begin{align*}
v \big|_{x_n =0} &= u \big|_{\Sigma} = 0 \\
\pa_i v \big|_{x_n =0} &= (D\Phi)_{ij} \pa_j u \big|_{\Sigma} = 0 
\end{align*}
and proceeding similarly for $\pa^{k-1} v / (\pa x^n)^{k-1}$, we have each $D^{\beta} v$ for $|\beta|<k$ as a linear combination of $D^{\alpha}u$($|\alpha|<k$) and hence $D^{\beta} v= 0$ for each $|\alpha|<k$. Hence, we have (check that this is an equivalent condition)
\begin{align*}
v = \frac{\pa v}{\pa x^n} = \cdots = \pa^{k-1} v / (\pa x^n)^{k-1} =0 \quad \text{on } \{ x_n =0 \}
\end{align*}
We can solve this, provided
\begin{align*}
b_{(0,\cdots,0, k)}(0,0, \cdots, 0, y) \neq 0 \quad \text{on } \{ x_n =0 \}
\end{align*}

Note if $|\alpha | = k$,
\begin{align*}
D^{\alpha}u = \frac{\pa^k v}{\pa y^k_n} (D\Phi^n)^{\alpha} + (\text{terms not involving } \frac{\pa^k v}{\pa y^k_n})
\end{align*}
So the coefficient of $\pa^k v / \pa y^k_n$ in
\begin{align*}
\sum_{|\alpha| =k} a_{\alpha}(D^{k-1}u, \cdots, u,x)D^{\alpha} u + a_0(D^{n-1}u, \cdots, u,x) =0
\end{align*}
is
\begin{align*}
b_{(0,\cdots,k)} = a_{\alpha}(D\Phi^n)^{\alpha}
\end{align*}
But $\Sigma = \{\Phi^n =0\}$ so $D\Phi^n \propto \gamma$. Therefore,
\begin{align*}
b_{(0,\cdots,k)} \neq 0 \quad \Leftrightarrow \quad \sum_{|\alpha|=k} a_{\alpha} (D\Phi^n)^{\alpha} \neq 0  \quad \Leftrightarrow \quad \sum_{|\alpha|=k} a_{\alpha} \gamma^{\alpha} \neq 0
\end{align*}
\s

\defi $\Sigma$ is a \textbf{non-characteristic} at $x\in \Sigma$ for the problem (\ref{dagger}) provided
\begin{align*}
\sum_{|\alpha| =k} a_{\alpha} (0,\cdots,0,x) \gamma^{\alpha}(x) \neq 0
\end{align*}
\s

Finally, we have a more general version of Cauchy-Kovalevskaya.
\s

\thm (Cauchy-Kovalevskaya Redux) Suppose $\Sigma \subset \reals^n$ is a real analytic hypersurface. If $\Sigma$ is non-characteristic for (\ref{dagger}) at $x\in \Sigma$, there exists a unique real analytic solution to (\ref{dagger}) in a neighbourhood of $x$.
\begin{proof}
\pf We have already seen that we can solve the problem for $v$ uniquely, then $u(x)  = v(\Phi(x))$ is the unique solution for (\ref{dagger})

\eop
\end{proof}
\s

\subsection*{Characteristic Surfaces for 2nd Order Linear PDE}

Consider the linear operator
\begin{align*}
Lu = \sum_{i,j=1}^n a_{ij}\frac{\pa^2 u}{\pa x_i \pa x_j} + \sum_{i=1}^n b_i \frac{\pa u}{\pa x^i} + cu
\end{align*}
with $a_{ij},b_i,c : \reals^n \rightarrow \reals$.
\s

Consider the Cauchy problem
\begin{align*}
Lu& = f \\
u &= \sum_{i=1}^n \xi^i \frac{\pa u}{\pa x^i} = 0 \quad \text{on } \Pi_{\xi} = \{ \xi \cdot x =0 \}
\end{align*}
$\Pi_{\xi}$ is characteristic at $x\in \reals^n$ if : 
\begin{align*}
\sigma_p (\xi, x) = \sum_{i,j=1}^n a_{ij}\xi^i \xi^j = 0
\end{align*}
$\sigma_p$ is the \textbf{principal symbol} of $L$. 
\s

\begin{itemize}
\item If $\sigma_p(\xi, x) >0$ for all $x$, $\xi \neq 0$, then no plane is characteristic, and such operations are called $\textbf{elliptic}$. 
\end{itemize}
\s

Let us restrict to the case where $a_{ij},b_i, c$ are constants. Suppose $b_i = c=0$ and $\Pi_{\xi}$ is characteristic. Then
\begin{align*}
u(x) = e^{i\lambda \xi \cdot x}
\end{align*}
solve $Lu =0$ for any $\lambda$. By taking $\lambda$ large, we can construct solutions to $Lu =0$ whose derivative (in the $\xi$ direction) is a large as we like. In particular, $Lu$ is very regular, but $u$ need not be. In the elliptic setting, this cannot happen. 
\s

\newday

(19th October, Friday)
\s

\subsection*{Criticisms/Shortcomings of Cauchy-Kovalevskaya}
\begin{itemize}
\item[1.] Real analyticity is (sometimes) too strong a condition. For example, if solutions of Maxwell's equations were required to be real analytic. We'd know electro-magnetic field everywhere if we could measure it in some small set. This is absurd.
\item[2.] We don't necessarily get continuous dependence on data in the form we would like.

\textbf{Example :} Consider Laplace's equation on $\reals^2$. $u_{xx} + u_{yy} = 0$, with Cauchy data $u(x,0) = \cos (kx)$, $u_y(x,0) =0$. This has a real analytic solution
\begin{align*}
u(x,y) = \cos (kx) \cosh (ky)
\end{align*}
We can check that $\sup_{x\in \reals} |u(x,0) \leq 1|$ but $\sup_{x\in \reals} |u(x,\epsilon)| \rightarrow \infty$ as $k\rightarrow \infty$ for all $\epsilon >0$.

\quad In fact, we can require as many derivatives of $u$ on $\{ y=0 \}$ to be bounded and we can still find solutions which are arbitrarily large at $y=\epsilon$. This Cauchy problem is \emph{not} well posed in $C^k$, as there is no continuous dependence on data.
\s
\end{itemize}
\s

These suggest the Cauchy problem for Laplace's equation is not the natural one to consider. 

\subsection*{Elliptic Boundary Value Problems}

A more natural problem arising in physics is the \textbf{Dirichlet Problem} : 
\begin{align*}
\Delta u &= 0\quad \text{in } U\subset \reals^n, \quad U \text{ open, bounded} \\
u &= g \quad \text{on } \pa U
\end{align*}

e.g. $u$ is electrostatic potential in a cavity whose walls are held at voltage $g$. 
\s

We shall develop methods to solve such problems. First we develop some technology.
%배고프다. 배꼽시계에 신호온다ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ

\subsection*{H\"{o}lder and Sobolev Spaces}

We need to discuss various function spaces in which to seek solutions our PDEs.

\subsubsection*{H\"{o}lder spaces}

Suppose $U\subset \reals^n$ is open. We write $u\in C^k(U)$ if $u:U\rightarrow \reals$ is $k$-times differentiable at each $x\in U$ and $D^{\alpha}$ is continuous on $U$ for all $|\alpha| \leq k$. This is not a Banach space, so we would like to restrict to a smaller complete space with a norm.

\quad We say $u\in C^k(\bar{U})$ if $u\in C^k (U)$ and $D^{\alpha}u$ is uniformly continuous and bounded on $U$ for each $|\alpha| \leq k$. We introduce a norm :
\begin{align*}
\norms{u}{C^k(\bar{U})} = \sum_{|\alpha|\leq k} \sup_{x\in U} |D^{\alpha}u(x)|
\end{align*}
With this norm, $C^k(\bar{U})$ is a Banach space. (*Be aware, that $C^k(\bar{U})$ seems to be constructed from the closure $\bar{U}$, but this is not true. It is constructed from $U$ and just depends on $U$. This matters when $U$ does not have a nice boundary e.g. if $U$ is a complement of the Cantor set$\cap [0,1]$, then $C^{k}(\bar{U})\neq C^{k} \cap [0,1]$).

\quad For $0< \gamma \leq 1$, we say that $u$ is \textbf{H\"{o}lder continuous with exponent $\gamma$} if there exists a constant $C\geq 0$ s.t.
\begin{align*}
|u(x)-u(y)|\leq C|x-y|^{\gamma} \quad \forall x,y \in U
\end{align*}
We define $\gamma^{\text{th}}$ \textbf{H\"{o}lder seminorm} by
\begin{align*}
[u]_{C^{0,\gamma}(\bar{U})} = \inf_{x,y\in U} \frac{|u(x)-u(y)|}{|x-y|^{\gamma}}
\end{align*}

\quad We say $u\in C^{k,\gamma}(\bar{U})$ if $u\in C^k(\bar{U})$ and $D^{\alpha}u$ is H\"{o}lder continuous, with exponent $\gamma$ for all $|\alpha|=k$. We define a norm : 
\begin{align*}
\norms{u}{C^{k,\gamma}(\bar{U})} = \norms{u}{C^k(\bar{U})} + \sum_{|\alpha|=k} [D^{\alpha} k]_{C^{0,\gamma}(\bar{U})}
\end{align*}
This is again a Banach space.

\subsubsection*{The Spaces $L^p(U)$, $L^p_{\text{loc}}(U)$}

For $U\subset\reals^n$ open, suppose $1\leq p<\infty$. We define the space $L^p(U)$ by
\begin{align*}
L^p(U) = \{ u:U\rightarrow \reals \text{ measurable}| \norms{u}{L^p(U)} <\infty \} / \sim
\end{align*}
where
\begin{align*}
\norms{u}{L^p(U)} = \begin{cases}
\big( \int_{U} |u(x)|^p dx \big)^{1/p} \quad \text{for } 1\leq p <\infty \\
\\
\text{assup}_x u(x) = \inf \{C\geq 0 : |u(x)| \leq C \text{ for almost every } x \}
\end{cases}
\end{align*}
and the $\sim$ is an equivalence relation defined by $u_1 \sim u_2$ \emph{if and only if} $u_1 = u_2$ almost everywhere.

$L^p(U)$ is a Banach space with norm $\norms{\cdot}{L^p(U)}$. Completeness follows from dominated convergence theorem.
\s

We define a local versions of $L^p(u)$ : we say $u\in L^p_{\text{loc}}(U)$ if $u\in L^p(V)$ for every $V \subset\subset U$ should be read \textbf{'$V$ is compactly contained in $U$'}, meaning there exists a compact $K$ s.t. $V\subset K \subset U$. Note $L^p_{\text{loc}}(U)$ is \emph{not} a Banach space.(it is a Fr\'{e}chet space)

\subsubsection*{Weak Derivatives}

We would like a notion of differentiability for $L^p$ functions. Since $L^p$ functions like to be integrated, it makes sense to seek a definition involving integration.
\s

\defi Suppose $u,v\in L^1_{\text{loc}}(U)$ and $\alpha$ is a multi-index. We say $v$ is a \textbf{$\alpha^{\text{th}}$ weak derivative} of $u$ if
\begin{align*}
(-1)^{|\alpha|} \int_{U} uD^{\alpha} \phi dx = \int_U v\phi dx \quad \forall \phi \in C^{\infty}_c(U)
\end{align*}
In other words, $u$, $v$ obey the correct integration of parts formula, when integrated against a test function $\phi \in C^{\infty}_c(U)$.
\s

$\star$ Check that if $D^{\alpha} u = v$, then $v$ is indeed also a weak derivative of $u$.
\s

\newday

(22nd October, Monday)
\s

(Example Classes : Group A - Thurs 2:00 - 3:30 pm, Group B - Thurs 4:00 - 5:30 pm, MR5)

(I am Group B)

(Submission in the problem class)

(Also a handout distributed - I'll try to add them in my notes!)
\s

\textbf{Last lecture :} Suppose $u,v\in L^1_{\text{loc}}(U)$ and $\alpha$ is a multi-index. We say $v$ is a \textbf{$\alpha^{\text{th}}$ weak derivative} of $u$ if
\begin{align*}
(-1)^{|\alpha|} \int_{U} uD^{\alpha} \phi dx = \int_U v\phi dx \quad \forall \phi \in C^{\infty}_c(U)
\end{align*}
In other words, $u$, $v$ obey the correct integration of parts formula, when integrated against a test function $\phi \in C^{\infty}_c(U) = \{u\in C^k(U) \,\,\,\, \forall k=1,2,\cdots | \text{supp}(U) \subset \subset U \}$.
\s

If $u\in C^k(U)$< then $D^{\alpha} u$ is a weak $\alpha$-derivative of $u$ for all $|\alpha| \leq k$ (use integration by part for proof)
\s

\newcommand{\loc}{L^1_{\text{loc}}}

\lem Suppose $v,\tilde{v} \in \loc (U)$ are both weak $\alpha$-derivatives of $u\in \loc (U)$. Then $v= \tilde{v}$ almost everywhere.
\begin{proof}
\pf \begin{align*}
(-1)^{|\alpha|} \int_U uD^{\alpha} \phi dx = \int_U v \phi dx = \int_U \tilde{v} \phi dx
\end{align*}
by the definition of $v$ and $\tilde{v}$ being $\alpha$-derivatives. Then
\begin{align*}
\int_U (v-\tilde{v}) \phi dx =0 \quad \forall \phi \in C^{\infty}_c (Y) \quad \Rightarrow \quad v= \tilde{v} \quad \text{a.e.}
\end{align*}

\eop
\end{proof}
\s

Since weak derivative is unique, we denote the $\alpha^{\text{th}}$ weak derivative of $u$ by $D^{\alpha} u$.

\s
\defi \begin{itemize}
\item We say $u \in \loc (U)$ belongs to the \textbf{Sobolev space} $W^{k,p}(U)$ ($k$ is the number of derivatives we want and $p$ is the exponent of $L^p$ space we are working on) if $u\in L^p(U)$ and the weak derivative $D^{\alpha} u$ exist for all $|\alpha| \leq k$ and $D^{\alpha} \in L^p(U)$.
\item If $p=2$ we write $H^k(U) = W^{k,2}(U)$.
\item We define the $W^{k,p}$ norm by
\begin{align*}
\norms{u}{W^{k,p}(U)} = \begin{cases}
\Big( \sum_{|\alpha|\leq k} \int_U |D^{\alpha} u|^p dx \Big)^{1/p} \quad 1\leq p <\infty \\
\sum_{|\alpha|\leq k} \norms{D^{\alpha} u }{L^{\infty}(U)} \quad p =\infty
\end{cases}
\end{align*}
(there are various equivalent ways of defining the norm)
\item We denote by $W_0^{k,p}(U)$ the completion of $C_c^{\infty}(U)$ in the $W^{k,p}(U)$-norm.
\end{itemize} 
\s

We will find out that these spaces will be useful in fining solutions of PDEs. In particular, the $H^k$ spaces will be useful.
\s

\textbf{Example :} Let $U = B_1(0) = \{ |x| <1 \} \subset \reals^n$. Set $u(x) = |x|^{-\lambda}$ for $x\in U \backslash \{0\}$ and $\lambda >0$. This diverges at $x=0$, so this is not a $C^{k}(U)$ function.

\quad Note for $x\neq 0$, $D_i u = - \lambda x_i /|x|^{\lambda +2}$. By considering test functions $\phi \in C_c^{\infty}(U \backslash \{0\})$, if $u$ is weakly differentiable, then the weak derivative must agree with this for $x\neq 0$. We can check $U\in L^1(U)$ if
\begin{align*}
\infty > \int_U |u| dx = \int_{B_1(0)} |x|^{-\lambda} dx = \omega_{n-1} \int_0^1 r^{-\lambda} r^{n-1} dr
\end{align*}
where $\omega_{n-1}$ is the area of $S^{n-1}$. The integral is finite if $n-1-\lambda >-1$, or equivalently $\lambda n$.

\quad A similar computation gives $- \lambda x_i/|x|^{\lambda +2} \in L^1(U)$, and equivalently $\lambda +1 <n$.

\quad Now we take $\lambda < n-1$. Now, suppose $\phi \in C^{\infty}_c(U)$.
\begin{align*}
-\int_{U \backslash B_{\epsilon}(0)} u\phi_{x_i} dx = \int_{U \backslash B_{\epsilon}(0)} u_{x_i} \phi dx - \int_{\pa B_{\epsilon}(0)} u \phi \nu^i dS
\end{align*}
where $\vec{\nu} = (\nu^1, \cdots, \nu^n)$ is the inward normal to $\partial B_{\epsilon}(0)$. Then integration by parts is justified since $u$ is smooth on $U \backslash B_{\epsilon}(0)$. We estimate
\begin{align*}
& \Big| \int_{\pa B_{\epsilon}(0)} u\phi \nu^i dS \Big| \leq \int_{\pa B_{\epsilon}(0)} |u\phi| dS \\
\leq & \norms{\phi}{L^{\infty}(U)} \int_{\pa B_{\epsilon}(0)} |u| dS = \norms{\phi}{L^{\infty}(U)} \int_{\pa B_{\epsilon}(0)} \epsilon^{-d} dS \\
= & \omega_{n-1} \norms{\phi}{L^{\infty}(U)} \epsilon^{n+1-\lambda} \xrightarrow{\epsilon \rightarrow 0} 0 \quad \text{for } \lambda < n-1
\end{align*}
Thus if $\lambda < n-1$, $|u|^{\lambda}$ has a $i^{\text{th}}$ weak derivative, equal to $-\lambda x_i /|x|^{\lambda+1}$. Moreover, $|Du| = -\lambda / |x|^{\lambda +1} \in L^p(U)$ \emph{if and only if} $p(\lambda +1) <n$. Also, $u\in L^p(U)$ \emph{if and only if} $p\lambda <n$.

\quad $\therefore$ $u\in W^{1,p}(U) \quad \Leftrightarrow \quad \lambda < \frac{n-p}{p}$.
\s

Notice that if $p>n$, we don't have an example of with $\lambda >0$ (look back once we've done some Sobolev embeddings).
\s

\thm  For each $k=1,2,\cdots$ and $1\leq p\leq \infty$. Then the space $W^{k,p}(U)$ is a Banach space.
\begin{proof}
We need some nice properties of weak derivatives, e.g. linearity, but we differ them to the example sheets.
\s

\pf We just prove the $p<\infty$ case here.
\begin{itemize}
\item[1.] Homogeneity and positivity of $\norms{\cdot}{W^{k,p}(U)}$ are obvious. To prove triangular inequality, recall Minkowski's inequality : 
\begin{align*}
\big( \sum_{i=1}^n |a_i + b_i|^p \big)^{1/p} \leq \big( \sum_{i=1}^n |a_i|^p \big)^{1/p} + \big( \sum_{i=1}^n |b_i|^p \big)^{1/p}
\end{align*}
We compute
\begin{align*}
\norms{u+v}{W^{k,p}(U)} &= \Big( \sum_{|\alpha| \leq k} \norms{D^{\alpha} u + D^{\alpha}v}{L^p (U)}^p \Big)^{1/p} \\
&\leq \Big( \sum_{|\alpha| \leq k} \big( \norms{D^{\alpha} u}{L^p (U)} + \norms{D^{\alpha} v}{L^p (U)} \big)^p \Big)^{1/p} \\
&\leq \big( \sum_{|\alpha| \leq k} \norms{D^{\alpha} u}{L^p (U)}^p \Big)^{1/p} + \Big( \sum_{|\alpha| \leq ks} \norms{D^{\alpha}v}{L^p (U)}^p \Big)^{1/p} \\
&= \norms{u}{W^{k,p}(U)} + \norms{v}{W^{k,p}(U)}
\end{align*}
\item[2.] For completeness, we note :
\begin{align*}
\norms{D^{\alpha} u}{L^p(U)} \leq \norms{u}{W^{k,p}(U)} \quad |\alpha| \leq k
\end{align*}
If $(u_l)_l$ is a Cauchy sequence in $W^{k,p}(U)$, then
\begin{align*}
\norms{D^{\alpha}(u_l - u_m)}{L^p(U)} \leq \norms{u_l -u_m}{W^{k,p}(U)}
\end{align*}
and hence $(D^{\alpha}u_l)_l$ is a Cauchy sequence in $L^p(U)$ for all $|\alpha| \leq k$. By completeness of $L^p (U)$, we may find $u^{\alpha} \in L^p(U)$ such that $D^{\alpha}u_l \rightarrow u^{\alpha}$ in $L^p(U)$ for each $|\alpha|\leq k$. In particular, let $u = u^{(0,\cdots, 0)}$
\begin{subproof}
\textbf{Claim : } $u^{\alpha} = D^{\alpha} u$ for each $|\alpha| \leq k$.

\pf To see this, let $\phi \in C^{\infty}_c(U)$. Then
\begin{align*}
(-1)^{|\alpha|} \int_U u_{l} D^{\alpha} \phi dx = \int_U D^{\alpha} u_l \phi dx
\end{align*}
Sending $l\rightarrow \infty$, we have $D^{\alpha} u_{l} \rightarrow u^{\alpha}$, $u_{l} \rightarrow u$ in $L^p(U)$. Therefore,
\begin{align*}
(-1) \int_U u D^{\alpha} \phi dx = \int_U u^{\alpha} \phi dx
\end{align*}
and $D^{\alpha} u = u^{\alpha} \in L^p(U)$ so $u\in W^{k,p}(U)$ and $u_l \rightarrow u$ in $W^{k,p}(U)$
\end{subproof}
\end{itemize}

\eop
\end{proof}
\s

\newday

(24th October, Wednesday)
\s

A point from last time 
\begin{itemize}
\item If $\phi \in C_c^{\infty} (U)$ and $u_l \rightarrow u$ in $L^p(U)$ then
\begin{align*}
\int_U u_l \phi dx \rightarrow \int_U u\phi dx
\end{align*}
This can be shown using H\"{o}lder inequality, e.g. $|\int_U (u_l -u)\phi dx| \leq \norms{u_l - u}{L^p} \norms{\phi}{L^q} \rightarrow 0$ as $l\rightarrow \infty$.
\end{itemize}
\s

\section*{Approximation of Functions in Sobolev Spaces}

It is often useful to know that we can approximate a certain object, e.g. a function, by some nicer object. In particular, for functions in Sobolev spaces, it is useful to be able to approximate by classically differentiable functions. We will show this is possible, with some assumptions on $U$.

\subsection*{Convolution and Smoothing}

A useful trick to smooth a function is \textbf{convolution with a smooth mollifier}.
\s

\defi \begin{itemize}
\item[(i)] Let \begin{align*}
\eta(x) = \begin{cases}
c e^{\frac{1}{|x|^2 -1}} \quad |x|<1 \\
0 \quad \quad |x| \geq 1
\end{cases}
\end{align*}
where $c$ is chosen such that $\int_{\reals^n} \eta(x) dx =1$.
\item[(ii)] For each $\epsilon >0$, set
\begin{align*}
\eta_{\epsilon}(x) = \frac{1}{\epsilon^n} \eta(\epsilon x)
\end{align*}
the standard mollifier.
\s

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{kernel}
\end{figure}
\s

We have that $\eta_{\epsilon}(x) \in C^{\infty}(\reals^n)$ and $\text{supp}(\eta_{\epsilon}) \subset B_{\epsilon}(0)$.
\end{itemize} 
\s

We let $U_{\epsilon} = \{ x\in U | \text{dist}(x,\partial U) > \epsilon \}$.
\s

\defi If $f: U\rightarrow \reals^n$ is locally integrable. i.e. $f\in L^1_{\text{loc}}(U)$. We define its $\epsilon$-mollification $f^{\epsilon} : U_{\epsilon} \rightarrow \reals$ by $f^{\epsilon} = \eta_\epsilon * f$, i.e.
\begin{align*}
f^{\epsilon}(x) = \int_U \eta_{\epsilon}(x-y) f(y)dy
\end{align*}
\s

Think of this as the average of $f$ in a neighbourhood of $x$, weighted by $\eta_{\epsilon}$ shifted to have its peak at $x$.
\s

\thm (Properties of Mollifiers) \begin{itemize}
\item[(i)] $f^{\epsilon} \in C^{\infty}(U_{\epsilon})$ and $D^{\alpha}f^{\epsilon} = \int_U D^{\alpha}_x \eta_{\epsilon}(x-y)f(y) dy$.
\item[(ii)] $f^{\epsilon}\rightarrow f$ almost everywhere as $\epsilon \rightarrow 0$.
\item[(iii)] If $f\in C^0 (U)$, then $f^{\epsilon} \rightarrow f$ uniformly on compact subsets of $U$.
\item[(iv)] If $1\leq p <\infty$ and $f \in L^p_{\text{loc}}(U)$ then $f^{\epsilon} \rightarrow f$ in $L^p_{\text{loc}}(U)$, i.e.
\begin{align*}
\norms{f^{\epsilon} - f}{L^p(V)} \rightarrow 0 \quad \forall V \subset\subset U
\end{align*}
\end{itemize}
\begin{proof}
\pf See handout
\end{proof}

\s

\lem Assume $u \in W^{k,p}(U)$ for some $1\leq p < \infty$. Set $u^{\epsilon} = \eta_{\epsilon} * u$ in $U_{\epsilon}$. Then
\begin{itemize}
\item[(i)] $u^{\epsilon} \in C^{\infty}(U_{\epsilon}) \quad \forall \epsilon >0$
\item[(ii)] If $V \subset \subset U$, then $u^{\epsilon} \rightarrow u$ in $W^{k,p}(V)$
\end{itemize}
\begin{proof}
\pf For (i), see handout.

For (ii), we claim $D^{\alpha} u^{\epsilon} = \eta_{\epsilon} * D^{\alpha} u$ for $|\alpha| \leq k$ in $U_{\epsilon}$, i.e. the derivative of $u^{\epsilon}$ is the $\epsilon$-mollifier of the derivative of $u$, i.e. derivatives commute with convolutions. To see this,
\begin{align*}
D^{\alpha} u^{\epsilon}(x) &= D^{\alpha} \int_U \eta_{\epsilon}(x-y) u(u) dy \\
&= \int_U D_x^{\alpha} \eta_x(x-y) u(y) dy \\
&= (-1)^{|\alpha|} \int_U D_y^{\alpha} \eta_x(x-y) u(y) dy \\
&= \int_U \eta_{\epsilon}(x-y) D^{\alpha} u(y) dy \quad \quad \text{(by definition of weak derivatives)} \\
&= \eta_{\epsilon} * D^{\alpha} u(x)
\end{align*}
Now, fix $V\subset \subset U$. By previous theorem, $\eta_{\epsilon} * D^{\alpha} u \rightarrow D^{\alpha} u$ in $L^p_{\text{loc}}(U)$. So $D^{\alpha} u^{\epsilon} \rightarrow D^{\alpha} u$. in $L^p_{\text{loc}}(U)$ for all $|\alpha| \leq k$. Thus :
\begin{align*}
\norms{u^{\epsilon}- u}{W^{k,p}(V)}^p = \sum_{|\alpha|\leq k} \norms{D^{\alpha} u^{\epsilon} - D^{\alpha}u}{L^p(U)}^p \rightarrow 0
\end{align*}
so indeed $u^{\epsilon} \rightarrow u$ in $W^{k,p}(U)$.

\eop
\end{proof}
\s

This tells us we can approximate $u$ in the interior of $U$ by smooth functions. We can do better :
\s

\thm (Global approximation by smooth functions) Suppose $U\subset \reals^n$ is open and \emph{bounded}, and suppose $u\in W^{k,p}(U)$ for some $1\leq p<\infty$. Then there exists functions $u_n \in C^{\infty}(U) \cap W^{k,p}(U)$ such that
\begin{align*}
u_n \rightarrow u \quad \text{in } W^{k,p}(U)
\end{align*}

Note, we do not assert $u_n \in C^{\infty}(\bar{U})$.
\begin{proof}
\pf \begin{itemize}
\item[1.] We have $U = \bigcup_{i=1}^{\infty} U_i$, where $U_i = \{x\in U \, : \, \text{dist}(x,\pa U) > 1/i \}$ for $i=1,2,\cdots$. Write $V_i = U_{i+3} \backslash \bar{U}_{i+1}$ and choose $V_0$ that is compact in $U$, so that we have $U = \bigcup_{i=1}^{\infty} V_i$. Let $\{\xi_i\}_{i=0}^{\infty}$ be a \emph{partition of unity subordinate} to $\{V_i \}$ so that
\begin{align*}
\begin{cases}
\xi_i \in C_c^{\infty}(V_i) \\
0\leq \xi_i \leq 1 \\
\sum_{i=0}^{\infty} \xi_i = 1 \quad \text{on } U
\end{cases}
\end{align*}
Suppose $u\in W^{k,p}(U)$. Then $\xi_i u \in W^{k,p}(U)$ and $\text{supp}(\xi_i u) \subset V_i$.
\item[2.] Fix $\delta >0$. For each $i$, choose $\epsilon_i$ sufficiently small that $u^i = \eta_{\epsilon_i} * (\xi_i u)$ satisfies
\begin{align*}
&\norms{u^i - \xi_i u}{W^{k,p}(U)} \leq \frac{\delta}{2^{i+1}} \quad i=0,1,2,\cdots \\
& \text{supp}(U_i) \subset W_i = U_{i+1} \backslash \bar{U}_i \quad i=1,2,\cdots
\end{align*}
\item[3.] Write $v = \sum_{i=0}^{\infty} u^i$, then $v \in C^{\infty}(U)$ as for each $V \subset\subset U$, the sum is finite. Since $u = \sum_{i=0}^{\infty} \xi_i u$, for each $V\subset\subset U$< we have
\begin{align*}
\norms{v-u}{W^{k,p}(U)} &\leq \sum_{i=0}^{\infty} \norms{u^i- \xi_i u}{W^{k,p}(U)} \\
& \leq \delta \sum_{i=0}^{\infty} 2^{-i-1} = \delta
\end{align*}
Take supremum over $V\subset\subset U$, and conclude $v \in W^{k,p}(U)$, and $\norms{v-u}{W^{k,p}(U)} \leq \delta$.
\end{itemize}

\eop
\end{proof}
\s

\newday





\end{document}



